{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "protecting-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suspected-negative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>569934458364813313</td>\n",
       "      <td>neutral</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cottopanama85</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir followback</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 10:58:58 -0800</td>\n",
       "      <td>ohio,panama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>568564006329434113</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PaulBEsteves</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united thanks for the help. Wish the phone re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 16:13:17 -0800</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>569643648910028801</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>runfixsteve</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 15:43:24 -0800</td>\n",
       "      <td>St. Augustine, Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>568864981917110272</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CLChicosky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 12:09:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>568929299350179840</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JW_Blocker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 16:24:49 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment     airline  \\\n",
       "0      567900433542488064          negative   Southwest   \n",
       "1      569989168903819264          positive   Southwest   \n",
       "2      568089179520954368          positive      United   \n",
       "3      568928195581513728          negative   Southwest   \n",
       "4      568594180014014464          negative      United   \n",
       "...                   ...               ...         ...   \n",
       "10975  569934458364813313           neutral    American   \n",
       "10976  568564006329434113          positive      United   \n",
       "10977  569643648910028801          negative  US Airways   \n",
       "10978  568864981917110272          negative  US Airways   \n",
       "10979  568929299350179840          negative      United   \n",
       "\n",
       "      airline_sentiment_gold           name negativereason_gold  \\\n",
       "0                        NaN  ColeyGirouard                 NaN   \n",
       "1                        NaN  WalterFaddoul                 NaN   \n",
       "2                        NaN      LocalKyle                 NaN   \n",
       "3                        NaN    amccarthy19                 NaN   \n",
       "4                        NaN        J_Okayy                 NaN   \n",
       "...                      ...            ...                 ...   \n",
       "10975                    NaN  Cottopanama85                 NaN   \n",
       "10976                    NaN   PaulBEsteves                 NaN   \n",
       "10977                    NaN    runfixsteve                 NaN   \n",
       "10978                    NaN     CLChicosky                 NaN   \n",
       "10979                    NaN     JW_Blocker                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "0                  0  @SouthwestAir I am scheduled for the morning, ...   \n",
       "1                  0  @SouthwestAir seeing your workers time in and ...   \n",
       "2                  0  @united Flew ORD to Miami and back and  had gr...   \n",
       "3                  0     @SouthwestAir @dultch97 that's horse radish üò§üê¥   \n",
       "4                  0  @united so our flight into ORD was delayed bec...   \n",
       "...              ...                                                ...   \n",
       "10975              0                            @AmericanAir followback   \n",
       "10976              0  @united thanks for the help. Wish the phone re...   \n",
       "10977              0  @usairways the. Worst. Ever. #dca #customerser...   \n",
       "10978              0  @nrhodes85: look! Another apology. DO NOT FLY ...   \n",
       "10979              1  @united you are by far the worst airline. 4 pl...   \n",
       "\n",
       "      tweet_coord              tweet_created              tweet_location  \\\n",
       "0             NaN  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1             NaN  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2             NaN  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3             NaN  2015-02-20 16:20:26 -0800                         NaN   \n",
       "4             NaN  2015-02-19 18:13:11 -0800                         NaN   \n",
       "...           ...                        ...                         ...   \n",
       "10975         NaN  2015-02-23 10:58:58 -0800                 ohio,panama   \n",
       "10976         NaN  2015-02-19 16:13:17 -0800                    Brooklyn   \n",
       "10977         NaN  2015-02-22 15:43:24 -0800      St. Augustine, Florida   \n",
       "10978         NaN  2015-02-20 12:09:15 -0800                         NaN   \n",
       "10979         NaN  2015-02-20 16:24:49 -0800                         NaN   \n",
       "\n",
       "                    user_timezone  \n",
       "0          Atlantic Time (Canada)  \n",
       "1      Central Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3          Atlantic Time (Canada)  \n",
       "4      Eastern Time (US & Canada)  \n",
       "...                           ...  \n",
       "10975                         NaN  \n",
       "10976  Eastern Time (US & Canada)  \n",
       "10977                         NaN  \n",
       "10978                         NaN  \n",
       "10979                         NaN  \n",
       "\n",
       "[10980 rows x 12 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\Dell\\\\Desktop\\\\ML\\\\twitter_sentimentAnalysis\\\\0000000000002747_training_twitter_x_y_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adult-cancellation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id                      0\n",
       "airline_sentiment             0\n",
       "airline                       0\n",
       "airline_sentiment_gold    10949\n",
       "name                          0\n",
       "negativereason_gold       10956\n",
       "retweet_count                 0\n",
       "text                          0\n",
       "tweet_coord               10204\n",
       "tweet_created                 0\n",
       "tweet_location             3550\n",
       "user_timezone              3577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "happy-healing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10980, 12)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "three-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline', 'airline_sentiment_gold',\n",
       "       'name', 'negativereason_gold', 'retweet_count', 'text', 'tweet_coord',\n",
       "       'tweet_created', 'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "korean-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "crucial-support",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "standard-barbados",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x23e6834e910\n",
      "0x23e6834e910\n"
     ]
    }
   ],
   "source": [
    "print(hex(id(df)))\n",
    "print(hex(id(df2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "signal-dimension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NaN\n",
       "1    NaN\n",
       "2    NaN\n",
       "3    NaN\n",
       "4    NaN\n",
       "Name: airline_sentiment_gold, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline_sentiment_gold\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "yellow-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               Washington D.C.\n",
       "1    Indianapolis, Indiana; USA\n",
       "2                      Illinois\n",
       "3                           NaN\n",
       "4                           NaN\n",
       "Name: tweet_location, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet_location\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "minus-development",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Atlantic Time (Canada)\n",
       "1    Central Time (US & Canada)\n",
       "2    Central Time (US & Canada)\n",
       "3        Atlantic Time (Canada)\n",
       "4    Eastern Time (US & Canada)\n",
       "Name: user_timezone, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"user_timezone\"][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "competent-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df[\"airline_sentiment_gold\"]\n",
    "del df[\"negativereason_gold\"]\n",
    "del df[\"tweet_coord\"]\n",
    "del df[\"tweet_created\"]\n",
    "del df[\"tweet_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "surface-concentration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment       0\n",
       "airline                 0\n",
       "name                    0\n",
       "retweet_count           0\n",
       "text                    0\n",
       "tweet_location          0\n",
       "user_timezone        3577\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tweet_location\"].fillna(\" \",inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "legal-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "df[\"airline_sentiment\"] = enc.fit_transform(df[\"airline_sentiment\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "explicit-denial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>retweet_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10980.000000</td>\n",
       "      <td>10980.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540164</td>\n",
       "      <td>0.080965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.759390</td>\n",
       "      <td>0.740303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       airline_sentiment  retweet_count\n",
       "count       10980.000000   10980.000000\n",
       "mean            0.540164       0.080965\n",
       "std             0.759390       0.740303\n",
       "min             0.000000       0.000000\n",
       "25%             0.000000       0.000000\n",
       "50%             0.000000       0.000000\n",
       "75%             1.000000       0.000000\n",
       "max             2.000000      44.000000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "social-brook",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "grand-stopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "smoking-certificate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " '@',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " '~'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "import string\n",
    "punctuations = list(string.punctuation)\n",
    "stop.update(punctuations)\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "respected-tractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "brilliant-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \",text)\n",
    "    words = word_tokenize(sentence)\n",
    "    output_words = []\n",
    "    for w in words:\n",
    "        if w.lower() not in stop:\n",
    "            pos_t = pos_tag([w])\n",
    "            clean_word = lem.lemmatize(w, pos = get_simple_pos(pos_t[0][1]))\n",
    "            output_words.append(clean_word.lower())\n",
    "    return (\" \".join(output_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "handled-teacher",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nrhodes look another apology fly usairways'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(df[\"text\"][10978])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fourth-eagle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Southwest\n",
       "1         Southwest\n",
       "2            United\n",
       "3         Southwest\n",
       "4            United\n",
       "            ...    \n",
       "10975      American\n",
       "10976        United\n",
       "10977    US Airways\n",
       "10978    US Airways\n",
       "10979        United\n",
       "Name: airline, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "armed-nickel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        @SouthwestAir I am scheduled for the morning, ...\n",
       "1        @SouthwestAir seeing your workers time in and ...\n",
       "2        @united Flew ORD to Miami and back and  had gr...\n",
       "3           @SouthwestAir @dultch97 that's horse radish üò§üê¥\n",
       "4        @united so our flight into ORD was delayed bec...\n",
       "                               ...                        \n",
       "10975                              @AmericanAir followback\n",
       "10976    @united thanks for the help. Wish the phone re...\n",
       "10977    @usairways the. Worst. Ever. #dca #customerser...\n",
       "10978    @nrhodes85: look! Another apology. DO NOT FLY ...\n",
       "10979    @united you are by far the worst airline. 4 pl...\n",
       "Name: text, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adverse-profit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"clean_tweets\"] = df[\"text\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "identified-lightweight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        southwestair schedule morning day fact yes sur...\n",
       "1        southwestair see worker time time go beyond lo...\n",
       "2        united flew ord miami back great crew service ...\n",
       "3                         southwestair dultch horse radish\n",
       "4        united flight ord delayed air force one last f...\n",
       "                               ...                        \n",
       "10975                               americanair followback\n",
       "10976    united thanks help wish phone rep could accomi...\n",
       "10977             usairways worst ever dca customerservice\n",
       "10978           nrhodes look another apology fly usairways\n",
       "10979    united far bad airline plane delay round trip ...\n",
       "Name: clean_tweets, Length: 10980, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"clean_tweets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "static-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "worldwide-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvc = CountVectorizer(max_features = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "accredited-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cvc.fit_transform(df[\"clean_tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ancient-humor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aadvantage',\n",
       " 'aafail',\n",
       " 'aal',\n",
       " 'aarp',\n",
       " 'abandon',\n",
       " 'abc',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'aboard',\n",
       " 'abq',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abuse',\n",
       " 'abysmal',\n",
       " 'ac',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accident',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'acct',\n",
       " 'accts',\n",
       " 'accurate',\n",
       " 'accuse',\n",
       " 'acknowledge',\n",
       " 'acknowledgment',\n",
       " 'across',\n",
       " 'act',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activate',\n",
       " 'active',\n",
       " 'activity',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'additional',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'addtl',\n",
       " 'admiral',\n",
       " 'admirals',\n",
       " 'admit',\n",
       " 'advance',\n",
       " 'advantage',\n",
       " 'advertise',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advisory',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'afternoon',\n",
       " 'age',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'aggressive',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agt',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahhhh',\n",
       " 'ahold',\n",
       " 'air',\n",
       " 'airbus',\n",
       " 'aircanada',\n",
       " 'aircraft',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlinegeeks',\n",
       " 'airlines',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airway',\n",
       " 'airways',\n",
       " 'aisle',\n",
       " 'alaska',\n",
       " 'albany',\n",
       " 'alert',\n",
       " 'ali',\n",
       " 'alive',\n",
       " 'allergy',\n",
       " 'alliance',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alternate',\n",
       " 'alternative',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'always',\n",
       " 'alwayslate',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americanair',\n",
       " 'americanairlines',\n",
       " 'americanview',\n",
       " 'amex',\n",
       " 'amm',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amybruni',\n",
       " 'ana',\n",
       " 'anamarketers',\n",
       " 'andrew',\n",
       " 'andrews',\n",
       " 'aneqxzr',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angry',\n",
       " 'ann',\n",
       " 'annettenaif',\n",
       " 'anniversary',\n",
       " 'announce',\n",
       " 'announcement',\n",
       " 'announces',\n",
       " 'annoy',\n",
       " 'annoyed',\n",
       " 'annricord',\n",
       " 'annual',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answerthephone',\n",
       " 'anthony',\n",
       " 'anticipate',\n",
       " 'antonio',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'apologise',\n",
       " 'apologize',\n",
       " 'apologizes',\n",
       " 'apology',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appear',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'application',\n",
       " 'apply',\n",
       " 'appointment',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'approach',\n",
       " 'appropriate',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approx',\n",
       " 'apps',\n",
       " 'apr',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aqjn',\n",
       " 'ar',\n",
       " 'arbitrary',\n",
       " 'ardent',\n",
       " 'area',\n",
       " 'argue',\n",
       " 'argument',\n",
       " 'arizona',\n",
       " 'armrest',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arrangement',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'article',\n",
       " 'aruba',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'ase',\n",
       " 'ashamed',\n",
       " 'asia',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'askpaypal',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'aspen',\n",
       " 'assault',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assign',\n",
       " 'assignment',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'associate',\n",
       " 'assult',\n",
       " 'assume',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'astound',\n",
       " 'asw',\n",
       " 'atc',\n",
       " 'athlete',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atrocious',\n",
       " 'attach',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attendee',\n",
       " 'attention',\n",
       " 'attentiveness',\n",
       " 'attitude',\n",
       " 'au',\n",
       " 'aug',\n",
       " 'august',\n",
       " 'auh',\n",
       " 'aus',\n",
       " 'austin',\n",
       " 'austinairport',\n",
       " 'australia',\n",
       " 'austrian',\n",
       " 'auto',\n",
       " 'automate',\n",
       " 'automatically',\n",
       " 'autoresponse',\n",
       " 'av',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'available',\n",
       " 'average',\n",
       " 'avgeek',\n",
       " 'aviation',\n",
       " 'avis',\n",
       " 'aviv',\n",
       " 'avoid',\n",
       " 'aw',\n",
       " 'await',\n",
       " 'award',\n",
       " 'aware',\n",
       " 'away',\n",
       " 'awe',\n",
       " 'awesome',\n",
       " 'awesomeness',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'aww',\n",
       " 'awww',\n",
       " 'ay',\n",
       " 'az',\n",
       " 'ba',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'backlog',\n",
       " 'backpack',\n",
       " 'backup',\n",
       " 'bad',\n",
       " 'badcustomerservice',\n",
       " 'badge',\n",
       " 'badly',\n",
       " 'badmgmt',\n",
       " 'badservice',\n",
       " 'bae',\n",
       " 'bag',\n",
       " 'bagage',\n",
       " 'baggage',\n",
       " 'baggagelost',\n",
       " 'bags',\n",
       " 'bahamas',\n",
       " 'bait',\n",
       " 'balance',\n",
       " 'ball',\n",
       " 'baltimore',\n",
       " 'ban',\n",
       " 'band',\n",
       " 'bandwidth',\n",
       " 'bangkok',\n",
       " 'bank',\n",
       " 'bankrupt',\n",
       " 'bar',\n",
       " 'barbados',\n",
       " 'barbara',\n",
       " 'barely',\n",
       " 'base',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basket',\n",
       " 'bathroom',\n",
       " 'battery',\n",
       " 'battierccipuppy',\n",
       " 'batting',\n",
       " 'battle',\n",
       " 'battles',\n",
       " 'battling',\n",
       " 'bay',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bdl',\n",
       " 'beach',\n",
       " 'beanie',\n",
       " 'beantownmatty',\n",
       " 'beat',\n",
       " 'beating',\n",
       " 'beatz',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'become',\n",
       " 'bed',\n",
       " 'beer',\n",
       " 'beg',\n",
       " 'begin',\n",
       " 'behalf',\n",
       " 'behavior',\n",
       " 'behind',\n",
       " 'belfast',\n",
       " 'believe',\n",
       " 'belize',\n",
       " 'bellagio',\n",
       " 'belong',\n",
       " 'belonging',\n",
       " 'belt',\n",
       " 'benefit',\n",
       " 'bereavement',\n",
       " 'bergstrom',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'bestairline',\n",
       " 'bestairlineever',\n",
       " 'bestemployees',\n",
       " 'bestflightever',\n",
       " 'bestfriends',\n",
       " 'besty',\n",
       " 'bet',\n",
       " 'betsy',\n",
       " 'better',\n",
       " 'beverage',\n",
       " 'beware',\n",
       " 'beyond',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bg',\n",
       " 'bgm',\n",
       " 'bgr',\n",
       " 'bhm',\n",
       " 'bicycle',\n",
       " 'big',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bill',\n",
       " 'billing',\n",
       " 'billion',\n",
       " 'bin',\n",
       " 'bio',\n",
       " 'bird',\n",
       " 'birmingham',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'biz',\n",
       " 'bk',\n",
       " 'black',\n",
       " 'blackhistorymonth',\n",
       " 'blah',\n",
       " 'blame',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'blasting',\n",
       " 'blatant',\n",
       " 'bless',\n",
       " 'blew',\n",
       " 'blizzard',\n",
       " 'block',\n",
       " 'blog',\n",
       " 'bloody',\n",
       " 'blow',\n",
       " 'blowing',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bluecarpet',\n",
       " 'bluemanity',\n",
       " 'bm',\n",
       " 'bna',\n",
       " 'board',\n",
       " 'boarded',\n",
       " 'boarding',\n",
       " 'boat',\n",
       " 'boeing',\n",
       " 'boeingairplanes',\n",
       " 'bogota',\n",
       " 'boise',\n",
       " 'bold',\n",
       " 'bom',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'book',\n",
       " 'booked',\n",
       " 'booking',\n",
       " 'boom',\n",
       " 'boot',\n",
       " 'booze',\n",
       " 'bora',\n",
       " 'border',\n",
       " 'bos',\n",
       " 'boston',\n",
       " 'bostonlogan',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bottle',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bougth',\n",
       " 'bounce',\n",
       " 'bound',\n",
       " 'bout',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'bp',\n",
       " 'bqn',\n",
       " 'bradley',\n",
       " 'brag',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'brandloveaffair',\n",
       " 'brandmance',\n",
       " 'brandssayingbae',\n",
       " 'brave',\n",
       " 'brazil',\n",
       " 'breach',\n",
       " 'break',\n",
       " 'breakdown',\n",
       " 'breakfast',\n",
       " 'breath',\n",
       " 'bretharold',\n",
       " 'brian',\n",
       " 'bridge',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'british',\n",
       " 'bro',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brokenpromises',\n",
       " 'brother',\n",
       " 'brothers',\n",
       " 'brought',\n",
       " 'browser',\n",
       " 'bruh',\n",
       " 'brushing',\n",
       " 'brutal',\n",
       " 'bs',\n",
       " 'bt',\n",
       " 'btr',\n",
       " 'bttr',\n",
       " 'btv',\n",
       " 'btw',\n",
       " 'buck',\n",
       " 'bucket',\n",
       " 'buddy',\n",
       " 'budget',\n",
       " 'buenos',\n",
       " 'buf',\n",
       " 'buffalo',\n",
       " 'bug',\n",
       " 'bull',\n",
       " 'bullshit',\n",
       " 'bum',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumper',\n",
       " 'bumping',\n",
       " 'bunch',\n",
       " 'burbank',\n",
       " 'burning',\n",
       " 'burningman',\n",
       " 'bus',\n",
       " 'bush',\n",
       " 'busiest',\n",
       " 'business',\n",
       " 'businessfirst',\n",
       " 'bussey',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buying',\n",
       " 'bv',\n",
       " 'bwi',\n",
       " 'ca',\n",
       " 'cab',\n",
       " 'cabin',\n",
       " 'cabo',\n",
       " 'cache',\n",
       " 'caffeine',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calendar',\n",
       " 'calgary',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'callback',\n",
       " 'called',\n",
       " 'caller',\n",
       " 'calling',\n",
       " 'camera',\n",
       " 'can',\n",
       " 'cana',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'cancelled',\n",
       " 'cancer',\n",
       " 'cancun',\n",
       " 'cant',\n",
       " 'canx',\n",
       " 'capa',\n",
       " 'capable',\n",
       " 'capacity',\n",
       " 'capital',\n",
       " 'capt',\n",
       " 'captain',\n",
       " 'captive',\n",
       " 'capture',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'cargo',\n",
       " 'carousel',\n",
       " 'carpet',\n",
       " 'carrier',\n",
       " 'carrieunderwood',\n",
       " 'carry',\n",
       " 'carryon',\n",
       " 'carryons',\n",
       " 'carseat',\n",
       " 'cart',\n",
       " 'case',\n",
       " 'cash',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'cater',\n",
       " 'catering',\n",
       " 'cattle',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'cb',\n",
       " 'cc',\n",
       " 'celebrate',\n",
       " 'cell',\n",
       " 'cellphone',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'century',\n",
       " 'ceo',\n",
       " 'cert',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'certificate',\n",
       " 'cessna',\n",
       " 'chair',\n",
       " 'chairman',\n",
       " 'challenge',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'channel',\n",
       " 'chaos',\n",
       " 'character',\n",
       " 'charge',\n",
       " 'charity',\n",
       " 'charleston',\n",
       " 'charlotte',\n",
       " 'charm',\n",
       " 'charter',\n",
       " 'chase',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'cheaper',\n",
       " 'cheapflights',\n",
       " 'cheat',\n",
       " 'check',\n",
       " 'checked',\n",
       " 'checkin',\n",
       " 'checkout',\n",
       " 'checkpoint',\n",
       " 'cheer',\n",
       " 'cheers',\n",
       " 'cheese',\n",
       " 'cherry',\n",
       " 'chi',\n",
       " 'chicago',\n",
       " 'chicken',\n",
       " 'child',\n",
       " 'china',\n",
       " 'cho',\n",
       " 'chocolate',\n",
       " 'choice',\n",
       " 'choose',\n",
       " 'chose',\n",
       " 'chrome',\n",
       " 'cincy',\n",
       " 'circle',\n",
       " 'circumstance',\n",
       " 'city',\n",
       " 'claim',\n",
       " 'claimed',\n",
       " 'clarification',\n",
       " 'clarify',\n",
       " 'class',\n",
       " 'cle',\n",
       " 'clean',\n",
       " 'cleaning',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'cleveland',\n",
       " 'click',\n",
       " 'client',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'clothes',\n",
       " 'clothing',\n",
       " 'cloud',\n",
       " 'clt',\n",
       " 'club',\n",
       " 'clue',\n",
       " 'cluster',\n",
       " 'cmh',\n",
       " 'cmon',\n",
       " 'cnn',\n",
       " 'co',\n",
       " 'coach',\n",
       " 'coast',\n",
       " 'coat',\n",
       " 'cocktail',\n",
       " 'code',\n",
       " 'coffee',\n",
       " 'coincidence',\n",
       " 'cold',\n",
       " 'colleague',\n",
       " 'collection',\n",
       " 'college',\n",
       " 'colo',\n",
       " 'color',\n",
       " 'columbia',\n",
       " 'columbus',\n",
       " 'com',\n",
       " 'combination',\n",
       " 'combine',\n",
       " 'comcast',\n",
       " 'come',\n",
       " 'comedy',\n",
       " 'comfort',\n",
       " 'comfortable',\n",
       " 'comfortably',\n",
       " 'comm',\n",
       " 'command',\n",
       " 'comment',\n",
       " 'commercial',\n",
       " 'commit',\n",
       " 'commitment',\n",
       " 'common',\n",
       " 'comms',\n",
       " 'communicate',\n",
       " 'communication',\n",
       " 'community',\n",
       " 'comp',\n",
       " 'companion',\n",
       " 'company',\n",
       " 'compare',\n",
       " 'compassion',\n",
       " 'compatible',\n",
       " 'comped',\n",
       " 'compensate',\n",
       " 'compensation',\n",
       " 'competition',\n",
       " 'competitor',\n",
       " 'complain',\n",
       " 'complains',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complicate',\n",
       " 'compliment',\n",
       " 'complimentary',\n",
       " 'compound',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'concentrate',\n",
       " 'concept',\n",
       " 'concern',\n",
       " 'concerned',\n",
       " 'concert',\n",
       " 'concourse',\n",
       " 'condescend',\n",
       " 'condition',\n",
       " 'condom',\n",
       " 'conection',\n",
       " 'conf',\n",
       " 'conference',\n",
       " 'confident',\n",
       " 'confirm',\n",
       " 'confirmation',\n",
       " 'confirmed',\n",
       " 'conflict',\n",
       " 'confuse',\n",
       " 'confusion',\n",
       " 'congrats',\n",
       " 'connect',\n",
       " 'connection',\n",
       " 'connector',\n",
       " 'consecutive',\n",
       " 'consider',\n",
       " 'consideration',\n",
       " 'considering',\n",
       " 'consistency',\n",
       " 'consistent',\n",
       " 'consistently',\n",
       " 'constant',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'consumer',\n",
       " 'cont',\n",
       " 'contact',\n",
       " 'contains',\n",
       " 'contd',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'continental',\n",
       " 'contingency',\n",
       " 'continually',\n",
       " 'continue',\n",
       " 'continued',\n",
       " 'continuous',\n",
       " 'contract',\n",
       " 'control',\n",
       " 'controller',\n",
       " 'convenient',\n",
       " 'conversation',\n",
       " 'conveyer',\n",
       " 'convince',\n",
       " 'convo',\n",
       " 'cool',\n",
       " 'coordinate',\n",
       " 'copilot',\n",
       " 'copy',\n",
       " 'corevalues',\n",
       " 'corner',\n",
       " 'corp',\n",
       " 'corporate',\n",
       " 'corporation',\n",
       " 'correct',\n",
       " 'correctly',\n",
       " 'cost',\n",
       " 'costa',\n",
       " 'costumer',\n",
       " 'cot',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'count',\n",
       " 'counter',\n",
       " 'counting',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'coupon',\n",
       " 'courier',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courteous',\n",
       " 'courtesy',\n",
       " 'cousin',\n",
       " 'cover',\n",
       " 'cowboycerrone',\n",
       " 'coworker',\n",
       " 'cp',\n",
       " 'cpap',\n",
       " 'cr',\n",
       " 'cracker',\n",
       " 'craft',\n",
       " 'craig',\n",
       " 'cramped',\n",
       " 'cranky',\n",
       " 'crap',\n",
       " 'crappy',\n",
       " 'crash',\n",
       " 'crashed',\n",
       " 'crate',\n",
       " 'crave',\n",
       " 'crazy',\n",
       " 'create',\n",
       " 'creates',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'crewmember',\n",
       " 'crewmembers',\n",
       " 'crisis',\n",
       " 'cross',\n",
       " 'crossed',\n",
       " 'crowd',\n",
       " 'cruel',\n",
       " 'cruise',\n",
       " 'cry',\n",
       " 'crying',\n",
       " 'cs',\n",
       " 'csr',\n",
       " 'ct',\n",
       " 'ctl',\n",
       " 'ctr',\n",
       " 'cuba',\n",
       " 'cue',\n",
       " 'culture',\n",
       " 'cun',\n",
       " 'cup',\n",
       " 'curb',\n",
       " 'curbside',\n",
       " 'curiosity',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cushion',\n",
       " 'cust',\n",
       " 'custexp',\n",
       " 'custom',\n",
       " 'customer',\n",
       " 'customers',\n",
       " 'customerservice',\n",
       " 'customerservicefail',\n",
       " 'custserv',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cuz',\n",
       " 'cvg',\n",
       " 'cvgairport',\n",
       " 'cx',\n",
       " 'cxl',\n",
       " 'cxld',\n",
       " 'cycle',\n",
       " 'dad',\n",
       " 'daily',\n",
       " 'dakota',\n",
       " 'dal',\n",
       " 'dale',\n",
       " 'dallas',\n",
       " 'dallaslovefield',\n",
       " 'damage',\n",
       " 'damn',\n",
       " 'dance',\n",
       " 'dang',\n",
       " 'danger',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darn',\n",
       " 'data',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'david',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'daytona',\n",
       " 'dbcvepn',\n",
       " 'dc',\n",
       " 'dca',\n",
       " 'de',\n",
       " 'deactivate',\n",
       " 'dead',\n",
       " 'deadhead',\n",
       " 'deaf',\n",
       " 'deal',\n",
       " 'dealing',\n",
       " 'deals',\n",
       " 'dealt',\n",
       " 'deane',\n",
       " 'dear',\n",
       " 'death',\n",
       " 'debacle',\n",
       " 'debate',\n",
       " 'debit',\n",
       " 'dec',\n",
       " 'december',\n",
       " 'decency',\n",
       " 'decent',\n",
       " 'decide',\n",
       " 'decided',\n",
       " 'decision',\n",
       " 'decisions',\n",
       " 'deck',\n",
       " 'decline',\n",
       " 'dedicate',\n",
       " 'deedee',\n",
       " 'deep',\n",
       " 'def',\n",
       " 'define',\n",
       " 'defines',\n",
       " 'definitely',\n",
       " 'definition',\n",
       " 'deflator',\n",
       " 'degree',\n",
       " 'deice',\n",
       " 'del',\n",
       " 'delay',\n",
       " 'delayed',\n",
       " 'delays',\n",
       " 'delete',\n",
       " 'delhi',\n",
       " 'delicious',\n",
       " 'delight',\n",
       " 'deliver',\n",
       " 'delivery',\n",
       " 'delta',\n",
       " 'deltaassist',\n",
       " 'den',\n",
       " 'denairport',\n",
       " 'denver',\n",
       " 'denverairport',\n",
       " 'deny',\n",
       " 'dep',\n",
       " 'depart',\n",
       " 'department',\n",
       " 'departs',\n",
       " 'departure',\n",
       " 'depends',\n",
       " 'deplane',\n",
       " 'deplaned',\n",
       " 'deplorable',\n",
       " 'dept',\n",
       " 'derekc',\n",
       " 'derrick',\n",
       " 'describe',\n",
       " 'desert',\n",
       " 'deserve',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'desire',\n",
       " 'desk',\n",
       " 'desktop',\n",
       " 'desperately',\n",
       " 'despite',\n",
       " 'dest',\n",
       " 'destination',\n",
       " 'destinationdragon',\n",
       " 'destinationdragons',\n",
       " 'destroyed',\n",
       " 'detail',\n",
       " 'detailed',\n",
       " 'detroit',\n",
       " 'develop',\n",
       " 'device',\n",
       " 'dfw',\n",
       " 'dfwairport',\n",
       " 'dia',\n",
       " 'diabetic',\n",
       " ...]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvc.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "environmental-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "chemical-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "prime-enemy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102914389799636\n"
     ]
    }
   ],
   "source": [
    "clf.fit(features, df['airline_sentiment'])\n",
    "accuracy = accuracy_score(clf.predict(features),df['airline_sentiment'])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "honey-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(r\"C:\\\\Users\\\\Dell\\\\Desktop\\\\ML\\\\twitter_sentimentAnalysis\\\\0000000000002747_test_twitter_x_test.csv\")\n",
    "test[\"tweet_location\"].fillna(\" \",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "prospective-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"clean_tweets\"] = test[\"text\"].apply(lambda x: clean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "diagnostic-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = cvc.transform(test[\"clean_tweets\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "compound-james",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 2, 0])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = clf.predict(test_features)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "activated-marine",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = enc.inverse_transform(test_predictions)\n",
    "np.savetxt(\"test_pred_Twitter.csv\",test_predictions,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-chapel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
